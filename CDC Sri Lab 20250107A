docker run --name mysql -e "TZ=Asia/Kolkata" -e MYSQL_ROOT_PASSWORD=etl -e MYSQL_USER=etl -e MYSQL_PASSWORD=etl -e MYSQL_DATABASE=mysqldb -d -p 13306:3306 --platform linux/x86_64 mysql:8.0.40-debian

root@7d20bb3c9487:/# apt update
root@7d20bb3c9487:/# apt -y install vim


root@a0cdb033f1d9:/# cat /etc/mysql/my.cnf | grep -v "#"


[mysqld]
pid-file        = /var/run/mysqld/mysqld.pid
socket          = /var/run/mysqld/mysqld.sock
datadir         = /var/lib/mysql
secure-file-priv= NULL

performance_schema=ON
server-id=8383
log_bin=mysql-bin
binlog_format=ROW
binlog_row_image=full

!includedir /etc/mysql/conf.d/
root@a0cdb033f1d9:/# 

% docker exec -it mysql bash
root@8e720d48a58e:/# mysql -u root -p -A
Enter password:   <<< etl
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 321
Server version: 8.0.40 MySQL Community Server - GPL

Copyright (c) 2000, 2024, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> use mysqldb;
Database changed
mysql> GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO "etl";
Query OK, 0 rows affected (0.05 sec)

mysql> FLUSH PRIVILEGES;
Query OK, 0 rows affected (0.02 sec)

mysql> 

show global variables where variable_name in ('binlog_format', 'binlog_row_image');


use mysqldb;


CREATE TABLE IF NOT EXISTS studentscrt
(
    
    mobile BIGINT,  
    certification TEXT,
    total_amt BIGINT,
    payment BIGINT,
    pending BIGINT,
    duedate TEXT,
    CONSTRAINT students_pkey PRIMARY KEY (mobile)
);



-------

docker run -d -e "TZ=Asia/Kolkata" -e "ACCEPT_EULA=Y" -e "SA_PASSWORD=Pass_01234" -e "MSSQL_PID=Developer" -p 1433:1433 --hostname mssql2022 --name mssql22 mcr.microsoft.com/mssql/server:2022-CU16-ubuntu-22.04

username: sa

% docker exec -it --user root mssql22 bash     
root@mssql2022:/# /opt/mssql/bin/mssql-conf set sqlagent.enabled true
SQL Server needs to be restarted in order to apply this setting. Please run
'systemctl restart mssql-server.service'.
root@mssql2022:/# systemctl restart mssql-server.service
bash: systemctl: command not found
root@mssql2022:/#

To check SQL Server Agent status --->

SELECT dss.[status], dss.[status_desc]
FROM   sys.dm_server_services dss
WHERE  dss.[servicename] LIKE N'SQL Server Agent (%';


IF EXISTS (  SELECT 1 
             FROM master.dbo.sysprocesses 
             WHERE program_name = N'SQLAgent - Generic Refresher')
BEGIN
    SELECT @@SERVERNAME AS 'InstanceName', 1 AS 'SQLServerAgentRunning'
END
ELSE 
BEGIN
    SELECT @@SERVERNAME AS 'InstanceName', 0 AS 'SQLServerAgentRunning'
END


IF EXISTS (SELECT 1 FROM sysprocesses WHERE LEFT(program_name, 8) = 'SQLAgent')
  PRINT 'Agent is running!'
ELSE
  PRINT 'Agent is not connected!';

 CREATE DATABASE mssqldb1;
 
 use mssqldb1;

SELECT
database_id,
name,
is_cdc_enabled
FROM sys.databases;

1	master	0
2	tempdb	0
3	model	0
4	msdb	0
5	mssqldb1	0

EXEC sys.sp_cdc_enable_db ; 

SELECT
database_id,
name,
is_cdc_enabled
FROM sys.databases;

1	master	0
2	tempdb	0
3	model	0
4	msdb	0
5	mssqldb1	1

Add Etl user with CDC rights -->

USE mssqldb1 ; 

CREATE LOGIN etl WITH PASSWORD = 'etl', CHECK_POLICY = OFF;
CREATE USER etl FOR LOGIN etl;
EXEC sp_addrolemember @rolename=db_owner, @membername=etl

USE MASTER;
GRANT VIEW SERVER STATE TO etl;

Enable CDC on DB and Tables level

DB level -->

SELECT
database_id,
name,
is_cdc_enabled
FROM sys.databases

USE mssqldb1 ; 
EXEC sys.sp_cdc_enable_db ; 

SELECT
database_id,
name,
is_cdc_enabled
FROM sys.databases;

CREATE TABLE studentname (
    mobile BIGINT NOT NULL,
    fname varchar(15) NOT NULL,
    mname varchar(15),
	emailid varchar(50) NOT NULL,	
    CONSTRAINT PK_studentname PRIMARY KEY (mobile)
);

Optional

Table level -->

EXEC sys.sp_cdc_help_change_data_capture;

SELECT
object_id,
SCHEMA_NAME(Schema_id) As [Schema Name],
name As [Table Name],
is_tracked_by_cdc
FROM sys.tables

901578250	dbo	systranschemas	0
933578364	cdc	change_tables	0
981578535	cdc	ddl_history	0
1013578649	cdc	lsn_time_mapping	0
1045578763	cdc	captured_columns	0
1077578877	cdc	index_columns	0
1253579504	dbo	studentname	0

EXEC sys.sp_cdc_enable_table
@source_schema = N'dbo',
@source_name   = N'studentname',
@role_name     = NULL,
@capture_instance = N'dbo_studentname'

Update mask evaluation will be disabled in net_changes_function because the CLR configuration option is disabled.
Job 'cdc.mssqldb1_capture' started successfully.
Job 'cdc.mssqldb1_cleanup' started successfully.

SELECT
object_id,
SCHEMA_NAME(Schema_id) As [Schema Name],
name As [Table Name],
is_tracked_by_cdc
FROM sys.tables


901578250	dbo	systranschemas	0
933578364	cdc	change_tables	0
981578535	cdc	ddl_history	0
1013578649	cdc	lsn_time_mapping	0
1045578763	cdc	captured_columns	0
1077578877	cdc	index_columns	0
1253579504	dbo	studentname	1
1285579618	cdc	dbo_studentname_CT	0

SELECT * from mssqldb1.dbo.studentname ;
select * from mssqldb1.cdc.dbo_studentname_CT;



---------


docker run -d --name pgsqlcdc -p 25432:5432 --hostname pgsqlcdc -e "TZ=Asia/Kolkata" -e PGDATA='/var/lib/postgresql/data' -e POSTGRES_DB='pgsqlcdcdb' -e POSTGRES_USER='etl' -e POSTGRES_PASSWORD='etl' postgres:latest

% docker run -d --name pgsqlcdc -p 25432:5432 --hostname pgsqlcdc -e "TZ=Asia/Kolkata" -e PGDATA='/var/lib/postgresql/data' -e POSTGRES_DB='pgsqlcdcdb' -e POSTGRES_USER='etl' -e POSTGRES_PASSWORD='etl' postgres:14.15-alpine3.21

show wal_level ;

ALTER SYSTEM SET wal_level = logical;

SELECT pg_reload_conf();

CREATE ROLE etl SUPERUSER CREATEDB CREATEROLE INHERIT LOGIN REPLICATION BYPASSRLS PASSWORD 'etl';

SELECT * FROM pg_user WHERE usename = 'etl';

grant all privileges on database "pgsqlcdcdb" to etl;


create schema students;	

CREATE TABLE students.pii (
    mobile BIGINT NOT NULL,
    pan_no VARCHAR(10),
    aadhaar_no VARCHAR(12),
    enrollment_no VARCHAR(14) not NULL,
    CONSTRAINT PK_studentname PRIMARY KEY (mobile)
);

---------

Step:1) Create PostgreSQL for Conduktor Console
docker run -d --name pgsqlcdk -p 15432:5432 --hostname pgsqlcdk -e PGDATA='/var/lib/postgresql/data' -e POSTGRES_DB='cdkpsqldb' -e POSTGRES_USER='etl' -e POSTGRES_PASSWORD='etl' postgres:latest

docker run -d --name pgsqlcdk -p 15432:5432 --hostname pgsqlcdk -e PGDATA='/var/lib/postgresql/data' -e POSTGRES_DB='cdkpsqldb' -e POSTGRES_USER='etl' -e POSTGRES_PASSWORD='etl' postgres:14.15-alpine3.21

Step:2) Create Conduktor Console Cortex
docker run -d --name cdkmntr -p 19009:9009 --hostname cdkmntr -p 19010:9010 --user root -e CDK_CONSOLE-URL="http://192.168.100.200:28080" conduktor/conduktor-console-cortex:latest

172.20.10.2
docker run -d --name cdkmntr -p 19009:9009 -p 19010:9010 --user root -e CDK_CONSOLE-URL="http://172.20.10.2:28080" conduktor/conduktor-console-cortex:latest

Step:3) Create Conduktor Console
docker run -d --name cdkcnsl -p 28080:8080 --hostname cdkcnsl -e CDK_DATABASE_URL="postgresql://etl:etl@192.168.100.200:15432/cdkpsqldb" -e CDK_MONITORING_CORTEX-URL="http://192.168.100.200:19009/" -e CDK_MONITORING_ALERT-MANAGER-URL="http://192.168.100.200:19010/" -e CDK_MONITORING_CALLBACK-URL="http://192.168.100.200:28080/monitoring/api/" -e CDK_MONITORING_NOTIFICATIONS-CALLBACK-URL="http://192.168.100.200:28080" conduktor/conduktor-console:latest

172.20.10.2
docker run -d --name cdkcnsl -p 28080:8080 --hostname cdkcnsl -e CDK_DATABASE_URL="postgresql://etl:etl@172.20.10.20:15432/cdkpsqldb" -e CDK_MONITORING_CORTEX-URL="http://172.20.10.2:19009/" -e CDK_MONITORING_ALERT-MANAGER-URL="http://172.20.10.2:19010/" -e CDK_MONITORING_CALLBACK-URL="http://172.20.10.2:28080/monitoring/api/" -e CDK_MONITORING_NOTIFICATIONS-CALLBACK-URL="http://172.20.10.2:28080" conduktor/conduktor-console:latest

Using the link

docker run -d --name cdkcnsl -p 28080:8080 --hostname cdkcnsl --link cdkmntr:cdkmntr --link pgsqlcdk:pgsqlcdk -e CDK_DATABASE_URL="postgresql://etl:etl@pgsqlcdk:5432/cdkpsqldb" -e CDK_MONITORING_CORTEX-URL="http://cdkmntr:9009/" -e CDK_MONITORING_ALERT-MANAGER-URL="http://cdkmntr:9010/" -e CDK_MONITORING_CALLBACK-URL="http://cdkcnsl:8080/monitoring/api/" -e CDK_MONITORING_NOTIFICATIONS-CALLBACK-URL="http://cdkcnsl:8080" conduktor/conduktor-console:latest

http://localhost:28080/console/home
Username: abc@srilab83.org
Pwd: Pass@1234

Step:4) Create Apacke Zookeeper & Kafka Broker 
docker run -d --name zkbk --hostname zkbk --user root -p 9092:9092 -p 2181:2181 apache/kafka:latest sleep infinitys 

nohup bin/zookeeper-server-start.sh config/zookeeper.properties &
bin/kafka-server-start.sh config/server.properties &

Step:5) Create Debezium Connector
docker run -d --name connect --link zkbk:kafka --link zkbk:zookeeper -p 18083:8083 -e CONFIG_STORAGE_TOPIC=sri_configstorage_topic -e OFFSET_STORAGE_TOPIC=sri_offsetstorage_topic -e KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter -e VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter quay.io/debezium/connect:latest

docker run -d --name connect2 --link zkbk:kafka --link zkbk:zookeeper -p 18083:8083 -e STATUS_STORAGE_TOPIC=my_connect_statuses -e CONFIG_STORAGE_TOPIC=sri_configstorage_topic -e OFFSET_STORAGE_TOPIC=sri_offsetstorage_topic quay.io/debezium/connect:latest

https://www.confluent.io/hub/wepay/kafka-connect-bigquery
docker exec -it --user root connect bash
cd /tmp
curl -o wepay-kafka-connect-bigquery-2.5.7.zip https://d2p6pa21dvn84.cloudfront.net/api/plugins/wepay/kafka-connect-bigquery/versions/2.5.7/wepay-kafka-connect-bigquery-2.5.7.zip
unzip wepay-kafka-connect-bigquery-2.5.7.zip
cp -pvr wepay-kafka-connect-bigquery-2.5.7/lib/* /kafka/libs/

bash-5.2# pwd
/kafka/connect
bash-5.2# cp -pvr /tmp/wepay-kafka-connect-bigquery-2.5.7 .

docker restart connect

sribqcdc@sriprojectgcp2.iam.gserviceaccount.com
sribqcdc	
BigQuery Data Editor
BigQuery Job User

Step:6) Integrate Debezium Connector with Kafka

http://localhost:28080/console/home >> Manage Cluster >> Click on existing Cluster >> Kafka Connect --> Add connector >> Name - Debezium-Connect ; Technical ID - debeziumconnect ; URL - http://192.168.100.200:18083 ; check select - Skip SSL Check ;  Authn - No Security >> Test connection --> Connected >> Save >> Back

Ste:7) Now Add the integration with Applicaiton MYSQL DB

MYSQL

{
	"key.converter": "org.apache.kafka.connect.json.JsonConverter",
	"value.converter": "org.apache.kafka.connect.json.JsonConverter",
	"schema.history.internal.kafka.bootstrap.servers": "192.168.100.200:9092",
	"key.converter.schemas.enable": "false",
	"connector.class": "io.debezium.connector.mysql.MySqlConnector",
	"database.user": "etl",
	"notification.sink.topic.name": "notificationsinktopic",
	"value.converter.schemas.enable": "false",
	"database.server.id": "8383",
	"database.port": "13306",
	"topic.prefix": "srilabcdc.topic.MySqlConnector1",
	"database.include.list": "mysqldb",
	"database.password": "etl",
	"schema.history.internal.kafka.topic": "schemahistorytopic",
	"database.hostname": "192.168.100.200"
}

MSSQL

{
	"database.encrypt": "false",
	"key.converter": "org.apache.kafka.connect.json.JsonConverter",
	"value.converter": "org.apache.kafka.connect.json.JsonConverter",
	"schema.history.internal.kafka.bootstrap.servers": "192.168.100.200:9092",
	"key.converter.schemas.enable": "false",
	"connector.class": "io.debezium.connector.sqlserver.SqlServerConnector",
	"database.history.kafka.bootstrap.servers": "192.168.100.200:9092",
	"database.user": "etl",
	"notification.sink.topic.name": "mssqldb1_notification_sink_topic",
	"value.converter.schemas.enable": "false",
	"database.history.kafka.topic": "dbhistory.DebeziumTestServer",
	"topic.prefix": "srilabcdc.topic.SqlServerConnector",
	"database.password": "etl",
	"schema.history.internal.kafka.topic": "schemahistory.fullfillment",
	"database.names": "mssqldb1",
	"database.hostname": "192.168.100.200",
	"database.port": "1433"
}

{
	"database.encrypt": "false",
	"key.converter": "org.apache.kafka.connect.json.JsonConverter",
	"value.converter": "org.apache.kafka.connect.json.JsonConverter",
	"schema.history.internal.kafka.bootstrap.servers": "192.168.100.200:9092",
	"key.converter.schemas.enable": "false",
	"connector.class": "io.debezium.connector.sqlserver.SqlServerConnector",
	"database.history.kafka.bootstrap.servers": "192.168.100.200:9092",
	"database.user": "etl",
	"notification.sink.topic.name": "mssqldb1_notification_sink_topic",
	"value.converter.schemas.enable": "false",
	"database.history.kafka.topic": "dbhistory.DebeziumTestServer",
	"topic.prefix": "srilabcdc.topic.SqlServerConnector",
	"database.password": "etl",
	"schema.history.internal.kafka.topic": "schemahistory.fullfillment",
	"database.names": "mssqldb1",
	"database.hostname": "192.168.100.200",
	"table.include.list": "dbo.studentname",
	"database.port": "1433"
}

PG:

{
	"value.converter": "org.apache.kafka.connect.json.JsonConverter",
	"key.converter.schemas.enable": "false",
	"database.user": "etl",
	"notification.sink.topic.name": "pgsqlcdcdb_notificationtopic",
	"value.converter.schemas.enable": "false",
	"database.hostname": "192.168.100.200",
	"topic.prefix": "srilabcdc.topic.PostgresConnector",
	"database.password": "etl",
	"plugin.name": "pgoutput",
	"key.converter": "org.apache.kafka.connect.json.JsonConverter",
	"connector.class": "io.debezium.connector.postgresql.PostgresConnector",
	"database.dbname": "pgsqlcdcdb",
	"database.port": "25432"
}

{
	"value.converter": "org.apache.kafka.connect.json.JsonConverter",
	"key.converter.schemas.enable": "false",
	"database.user": "etl",
	"notification.sink.topic.name": "pgsqlcdcdb_notificationtopic",
	"value.converter.schemas.enable": "false",
	"database.hostname": "192.168.100.200",
	"schema.include.list": "course",
	"topic.prefix": "srilabcdc.topic.PostgresConnector",
	"database.password": "etl",
	"plugin.name": "pgoutput",
	"key.converter": "org.apache.kafka.connect.json.JsonConverter",
	"connector.class": "io.debezium.connector.postgresql.PostgresConnector",
	"database.dbname": "pgsqlcdcdb",
	"table.include.list": "course.studentcert",
	"database.port": "5432"
}


	"value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "key.converter": "org.apache.kafka.connect.json.JsonConverter",
	"value.converter.schemas.enable": "false",
	"key.converter.schemas.enable": "false",


docker cp Desktop/sriprojectgcp2-4105de7c5991.json connect:/sribqcdc-sriprojectgcp2.json

BQ Sink

/sriprojectgcp2-a3c8eb421ec7.json

Working 21-Jan2024 0233 AM

{
	"topics.regex": "srilabcdc.topic.*",
	"transforms.extractAfterData.drop.tombstones": "false",
	"allowNewBigQueryFields": "true",
	"transforms.regexTopicRename.type": "org.apache.kafka.connect.transforms.RegexRouter",
	"transforms.extractAfterData.type": "io.debezium.transforms.ExtractNewRecordState",
	"autoCreateTables": "false",
	"consumer.auto.offset.reset": "earliest",
	"key.converter.schemas.enable": "false",
	"connector.class": "com.wepay.kafka.connect.bigquery.BigQuerySinkConnector",
	"transforms.regexTopicRename.replacement": "$1_$2",
	"schemaRetriever": "com.wepay.kafka.connect.bigquery.retrieve.IdentitySchemaRetriever",
	"sanitizeTopics": "true",
	"value.converter.schemas.enable": "false",
	"allBQFieldsNullable": "true",
	"transforms": "regexTopicRename,ConvertTimestamp,extractAfterData",
	"defaultDataset": "sri_cdc_dataset202501202328",
	"key.converter": "org.apache.kafka.connect.json.JsonConverter",
	"project": "sriprojectgcp2",
	"value.converter": "org.apache.kafka.connect.json.JsonConverter",
	"transforms.ConvertTimestamp.field": "DATESTAMP",
	"tasks.max": "1",
	"transforms.ConvertTimestamp.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
	"transforms.ConvertTimestamp.target.type": "Timestamp",
	"transforms.regexTopicRename.regex": "(.*).topic.(.*)",
	"keyfile": "/sribqcdc-sriprojectgcp2.json"
}

https://console.cloud.google.com/bigquery?ws=!1m5!1m4!4m3!1ssriprojectgcp2!2ssri_cdc_dataset202501202328!3ssrilabcdc_SqlServerConnector


sriprojectgcp2.sri_cdc_dataset202501202328.srilabcdc_SqlServerConnector

{
"connector.class": "com.wepay.kafka.connect.bigquery.BigQuerySinkConnector",
		"tasks.max": "1",
		"consumer.auto.offset.reset": "earliest",
		"topics.regex": "srilabcdc.topic.*",
		"sanitizeTopics": "true",
		"autoCreateTables": "true",
		"keyfile": "/sribqcdc-sriprojectgcp2.json",
		"schemaRetriever": "com.wepay.kafka.connect.bigquery.retrieve.IdentitySchemaRetriever",
		"project": "sriprojectgcp2",
		"defaultDataset": "sri_cdc_dataset202501202328",
		"allBQFieldsNullable": true,
		"allowNewBigQueryFields": true
	}


{
"connector.class": "com.wepay.kafka.connect.bigquery.BigQuerySinkConnector",
		"tasks.max": "1",
		"consumer.auto.offset.reset": "earliest",
		"topics.regex": "srilabcdc.topic.*",
		"sanitizeTopics": "true",
		"autoCreateTables": "true",
		"keyfile": "/sribqcdc-sriprojectgcp2.json",
		"schemaRetriever": "com.wepay.kafka.connect.bigquery.retrieve.IdentitySchemaRetriever",
		"project": "sriprojectgcp2",
		"defaultDataset": "sri_cdc_dataset202501202328",
		"allBQFieldsNullable": true,
		"allowNewBigQueryFields": true,
		"transforms": "regexTopicRename,extractAfterData",
		"transforms.regexTopicRename.type": "org.apache.kafka.connect.transforms.RegexRouter",
		"transforms.regexTopicRename.regex": "debezium.inventory.(.*)",
		"transforms.regexTopicRename.replacement": "$1",
		"transforms.extractAfterData.type": "io.debezium.transforms.ExtractNewRecordState"
	}

2025-Jan-26 Working

MSSQL

{
	"database.encrypt": "false",
	"schema.history.internal.kafka.bootstrap.servers": "192.168.100.200:9092",
	"connector.class": "io.debezium.connector.sqlserver.SqlServerConnector",
	"database.history.kafka.bootstrap.servers": "192.168.100.200:9092",
	"database.user": "etl",
	"notification.sink.topic.name": "mssqldb1_notification_sink_topic",
	"database.port": "1433",
	"topic.prefix": "srilabcdc.topic.SqlServerConnector",
	"database.password": "etl",
	"schema.history.internal.kafka.topic": "schemahistory.fullfillment",
	"database.names": "mssqldb1",
	"database.hostname": "192.168.100.200"
}

BQ

{
	"topics.regex": "srilabcdc.topic.*",
	"allowNewBigQueryFields": "true",
	"transforms.regexTopicRename.type": "org.apache.kafka.connect.transforms.RegexRouter",
	"project": "sriprojectgcp2",
	"transforms.extractAfterData.type": "io.debezium.transforms.ExtractNewRecordState",
	"autoCreateTables": "true",
	"tasks.max": "1",
	"consumer.auto.offset.reset": "earliest",
	"connector.class": "com.wepay.kafka.connect.bigquery.BigQuerySinkConnector",
	"transforms.regexTopicRename.replacement": "$1",
	"schemaRetriever": "com.wepay.kafka.connect.bigquery.retrieve.IdentitySchemaRetriever",
	"sanitizeTopics": "true",
	"allBQFieldsNullable": "true",
	"transforms": "regexTopicRename,extractAfterData",
	"defaultDataset": "srilabcdc",
	"transforms.regexTopicRename.regex": "srilabcdc.topic.(.*)",
	"keyfile": "/sriprojectgcp2-a3c8eb421ec7.json"
}


2025-01-25 22:18:54,918 INFO   ||  WorkerSinkTask{id=BigQuerySinkConnector-0} Sink task finished initialization and start   [org.apache.kafka.connect.runtime.WorkerSinkTask]
2025-01-25 22:18:54,918 INFO   ||  WorkerSinkTask{id=BigQuerySinkConnector-0} Executing sink task   [org.apache.kafka.connect.runtime.WorkerSinkTask]
2025-01-25 22:18:54,932 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Cluster ID: KQmEIsBASHyQtI5NlmlxkA   [org.apache.kafka.clients.Metadata]
2025-01-25 22:18:54,932 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Discovered group coordinator 192.168.100.200:9092 (id: 2147483647 rack: null)   [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator]
2025-01-25 22:18:54,933 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] (Re-)joining group   [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator]
2025-01-25 22:18:54,947 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Request joining group due to: need to re-join with the given member-id: connector-consumer-BigQuerySinkConnector-0-e00ba080-c129-41fb-b5b6-943922aaa130   [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator]
2025-01-25 22:18:54,947 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] (Re-)joining group   [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator]
2025-01-25 22:18:54,953 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-BigQuerySinkConnector-0-e00ba080-c129-41fb-b5b6-943922aaa130', protocol='range'}   [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator]
2025-01-25 22:18:54,954 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Finished assignment for group at generation 1: {connector-consumer-BigQuerySinkConnector-0-e00ba080-c129-41fb-b5b6-943922aaa130=Assignment(partitions=[srilabcdc.topic.SqlServerConnector.mssqldb1.dbo.studentname-0, srilabcdc.topic.SqlServerConnector-0])}   [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator]
2025-01-25 22:18:54,958 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-BigQuerySinkConnector-0-e00ba080-c129-41fb-b5b6-943922aaa130', protocol='range'}   [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator]
2025-01-25 22:18:54,958 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Notifying assignor about the new Assignment(partitions=[srilabcdc.topic.SqlServerConnector.mssqldb1.dbo.studentname-0, srilabcdc.topic.SqlServerConnector-0])   [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator]
2025-01-25 22:18:54,958 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Adding newly assigned partitions: srilabcdc.topic.SqlServerConnector-0, srilabcdc.topic.SqlServerConnector.mssqldb1.dbo.studentname-0   [org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker]
2025-01-25 22:18:54,963 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Found no committed offset for partition srilabcdc.topic.SqlServerConnector.mssqldb1.dbo.studentname-0   [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator]
2025-01-25 22:18:54,963 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Found no committed offset for partition srilabcdc.topic.SqlServerConnector-0   [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator]
2025-01-25 22:18:54,967 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Resetting offset for partition srilabcdc.topic.SqlServerConnector.mssqldb1.dbo.studentname-0 to position FetchPosition{offset=1855, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.100.200:9092 (id: 0 rack: null)], epoch=0}}.   [org.apache.kafka.clients.consumer.internals.SubscriptionState]
2025-01-25 22:18:54,967 INFO   ||  [Consumer clientId=connector-consumer-BigQuerySinkConnector-0, groupId=connect-BigQuerySinkConnector] Resetting offset for partition srilabcdc.topic.SqlServerConnector-0 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.100.200:9092 (id: 0 rack: null)], epoch=0}}.   [org.apache.kafka.clients.consumer.internals.SubscriptionState]
2025-01-25 22:18:59,965 INFO   ||  172.17.0.1 - - [25/Jan/2025:22:18:59 +0000] "GET /connectors?expand=info&expand=status HTTP/1.1" 200 2064 "-" "Apache-HttpClient/4.5.14 (Java/21.0.5)" 16   [org.apache.kafka.connect.runtime.rest.RestServer]
2025-01-25 22:19:00,155 INFO   ||  Attempting to create table `srilabcdc`.`SqlServerConnector_mssqldb1_dbo_studentname` with schema Schema{fields=[Field{name=mobile, type=INTEGER, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null}, Field{name=fname, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null}, Field{name=mname, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null}, Field{name=emailid, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null}]}   [com.wepay.kafka.connect.bigquery.SchemaManager]


Refer: https://infinitelambda.com/postgresql-bigquery-sync-pipeline-debezium-kafka/


sriprojectgcp2.srilabcdc.MySqlConnector_mysqldb_studentscrt
sriprojectgcp2.srilabcdc.PostgresConnector_students_pii
sriprojectgcp2.srilabcdc.SqlServerConnector_mssqldb1_dbo_studentname

Not Working



{
	"value.converter": "org.apache.kafka.connect.json.JsonConverter",
	"key.converter": "org.apache.kafka.connect.json.JsonConverter",
	"value.converter.schemas.enable": "false",
	"key.converter.schemas.enable": "false",
	"topics.regex": "srilabcdc.topic.*",
	"allowNewBigQueryFields": "true",
	"transforms.regexTopicRename.type": "org.apache.kafka.connect.transforms.RegexRouter",
	"project": "sriprojectgcp2",
	"transforms.extractAfterData.type": "io.debezium.transforms.ExtractNewRecordState",
	"autoCreateTables": "true",
	"tasks.max": "1",
	"consumer.auto.offset.reset": "earliest",
	"connector.class": "com.wepay.kafka.connect.bigquery.BigQuerySinkConnector",
	"transforms.regexTopicRename.replacement": "$1",
	"schemaRetriever": "com.wepay.kafka.connect.bigquery.retrieve.IdentitySchemaRetriever",
	"sanitizeTopics": "true",
	"allBQFieldsNullable": "true",
	"transforms": "regexTopicRename,extractAfterData",
	"defaultDataset": "srilabcdc",
	"transforms.regexTopicRename.regex": "srilabcdc.topic.(.*)",
	"keyfile": "/sriprojectgcp2-a3c8eb421ec7.json"
}

Redis Sink

https://d2p6pa21dvn84.cloudfront.net/api/plugins/jcustenborder/kafka-connect-redis/versions/0.0.8/jcustenborder-kafka-connect-redis-0.0.8.zip

Step:8) Set-up OSS Redis Stack
docker run -d --name cache -p 16379:6379 -p 18001:8001 -e REDIS_ARGS="--save 360 1 --save 30 100 --save 6 1000 --appendonly yes --protected-mode no --appendfsync everysec" redis/redis-stack:latest

Step:9) Run the PYthon Programe App to integrate Kafka Topic Message as CDC.

Topic we will choose is - MySqlConnector1.mysqldb.custinfo

*** Bingo!!!!
Create CDC is Successfull !

insert into custinfo (
mobile, pan_no, aadhaar_no, agreement_no)
values ('9999910049', 'BAAAA0047B', '12345679947', '202501072348');

SELECT * FROM custinfo WHERE mobile=9999910046;

UPDATE custinfo SET pan_no='BAAAA0049C', aadhaar_no='12345679949' WHERE mobile='9999910049';

DELETE FROM custinfo WHERE mobile='9999910049';


2025-01-07 18:27:19,567 - my_logger - INFO - Raw value: b'{"before":null,"after":{"mobile":9999910049,"pan_no":"BAAAA0047B","aadhaar_no":12345679947,"agreement_no":202501072348},"source":{"version":"2.7.3.Final","connector":"mysql","name":"MySqlConnector1","ts_ms":1736274439000,"snapshot":"false","db":"mysqldb","sequence":null,"ts_us":1736274439000000,"ts_ns":1736274439000000000,"table":"custinfo","server_id":8383,"gtid":null,"file":"mysql-bin.000013","pos":11558,"row":0,"thread":2245,"query":null},"transaction":null,"op":"c","ts_ms":1736274439455,"ts_us":1736274439455879,"ts_ns":1736274439455879460}'
2025-01-07 18:27:19,574 - my_logger - INFO - Raw key: b'{"mobile":9999910049}'
2025-01-07 18:27:19,574 - my_logger - INFO - Decoded value: {"before":null,"after":{"mobile":9999910049,"pan_no":"BAAAA0047B","aadhaar_no":12345679947,"agreement_no":202501072348},"source":{"version":"2.7.3.Final","connector":"mysql","name":"MySqlConnector1","ts_ms":1736274439000,"snapshot":"false","db":"mysqldb","sequence":null,"ts_us":1736274439000000,"ts_ns":1736274439000000000,"table":"custinfo","server_id":8383,"gtid":null,"file":"mysql-bin.000013","pos":11558,"row":0,"thread":2245,"query":null},"transaction":null,"op":"c","ts_ms":1736274439455,"ts_us":1736274439455879,"ts_ns":1736274439455879460}
2025-01-07 18:27:19,574 - my_logger - INFO - Decoded key: {"mobile":9999910049}
2025-01-07 18:27:19,574 - my_logger - INFO - CDC OPeration is: c
2025-01-07 18:27:19,580 - my_logger - INFO - c operation: Updated Redis Hash: MySqlConnector1.mysqldb.custinfo[{"mobile":9999910049}] -> {'before': None, 'after': {'mobile': 9999910049, 'pan_no': 'BAAAA0047B', 'aadhaar_no': 12345679947, 'agreement_no': 202501072348}, 'source': {'version': '2.7.3.Final', 'connector': 'mysql', 'name': 'MySqlConnector1', 'ts_ms': 1736274439000, 'snapshot': 'false', 'db': 'mysqldb', 'sequence': None, 'ts_us': 1736274439000000, 'ts_ns': 1736274439000000000, 'table': 'custinfo', 'server_id': 8383, 'gtid': None, 'file': 'mysql-bin.000013', 'pos': 11558, 'row': 0, 'thread': 2245, 'query': None}, 'transaction': None, 'op': 'c', 'ts_ms': 1736274439455, 'ts_us': 1736274439455879, 'ts_ns': 1736274439455879460}
2025-01-07 18:27:19,584 - my_logger - INFO - Offset committed for message at offset: 75
2025-01-07 18:27:33,144 - my_logger - INFO - Raw value: b'{"before":{"mobile":9999910049,"pan_no":"BAAAA0047B","aadhaar_no":12345679947,"agreement_no":202501072348},"after":{"mobile":9999910049,"pan_no":"BAAAA0049C","aadhaar_no":12345679949,"agreement_no":202501072348},"source":{"version":"2.7.3.Final","connector":"mysql","name":"MySqlConnector1","ts_ms":1736274452000,"snapshot":"false","db":"mysqldb","sequence":null,"ts_us":1736274452000000,"ts_ns":1736274452000000000,"table":"custinfo","server_id":8383,"gtid":null,"file":"mysql-bin.000013","pos":11893,"row":0,"thread":2245,"query":null},"transaction":null,"op":"u","ts_ms":1736274452731,"ts_us":1736274452731545,"ts_ns":1736274452731545008}'
2025-01-07 18:27:33,145 - my_logger - INFO - Raw key: b'{"mobile":9999910049}'
2025-01-07 18:27:33,146 - my_logger - INFO - Decoded value: {"before":{"mobile":9999910049,"pan_no":"BAAAA0047B","aadhaar_no":12345679947,"agreement_no":202501072348},"after":{"mobile":9999910049,"pan_no":"BAAAA0049C","aadhaar_no":12345679949,"agreement_no":202501072348},"source":{"version":"2.7.3.Final","connector":"mysql","name":"MySqlConnector1","ts_ms":1736274452000,"snapshot":"false","db":"mysqldb","sequence":null,"ts_us":1736274452000000,"ts_ns":1736274452000000000,"table":"custinfo","server_id":8383,"gtid":null,"file":"mysql-bin.000013","pos":11893,"row":0,"thread":2245,"query":null},"transaction":null,"op":"u","ts_ms":1736274452731,"ts_us":1736274452731545,"ts_ns":1736274452731545008}
2025-01-07 18:27:33,146 - my_logger - INFO - Decoded key: {"mobile":9999910049}
2025-01-07 18:27:33,148 - my_logger - INFO - CDC OPeration is: u
2025-01-07 18:27:33,160 - my_logger - INFO - u operation: Updated Redis Hash: MySqlConnector1.mysqldb.custinfo[{"mobile":9999910049}] -> {'before': {'mobile': 9999910049, 'pan_no': 'BAAAA0047B', 'aadhaar_no': 12345679947, 'agreement_no': 202501072348}, 'after': {'mobile': 9999910049, 'pan_no': 'BAAAA0049C', 'aadhaar_no': 12345679949, 'agreement_no': 202501072348}, 'source': {'version': '2.7.3.Final', 'connector': 'mysql', 'name': 'MySqlConnector1', 'ts_ms': 1736274452000, 'snapshot': 'false', 'db': 'mysqldb', 'sequence': None, 'ts_us': 1736274452000000, 'ts_ns': 1736274452000000000, 'table': 'custinfo', 'server_id': 8383, 'gtid': None, 'file': 'mysql-bin.000013', 'pos': 11893, 'row': 0, 'thread': 2245, 'query': None}, 'transaction': None, 'op': 'u', 'ts_ms': 1736274452731, 'ts_us': 1736274452731545, 'ts_ns': 1736274452731545008}
2025-01-07 18:27:33,167 - my_logger - INFO - Offset committed for message at offset: 76
2025-01-07 18:27:50,818 - my_logger - INFO - Raw value: b'{"before":{"mobile":9999910049,"pan_no":"BAAAA0049C","aadhaar_no":12345679949,"agreement_no":202501072348},"after":null,"source":{"version":"2.7.3.Final","connector":"mysql","name":"MySqlConnector1","ts_ms":1736274470000,"snapshot":"false","db":"mysqldb","sequence":null,"ts_us":1736274470000000,"ts_ns":1736274470000000000,"table":"custinfo","server_id":8383,"gtid":null,"file":"mysql-bin.000013","pos":12257,"row":0,"thread":2245,"query":null},"transaction":null,"op":"d","ts_ms":1736274470622,"ts_us":1736274470622622,"ts_ns":1736274470622622128}'
2025-01-07 18:27:50,820 - my_logger - INFO - Raw key: b'{"mobile":9999910049}'
2025-01-07 18:27:50,820 - my_logger - INFO - Decoded value: {"before":{"mobile":9999910049,"pan_no":"BAAAA0049C","aadhaar_no":12345679949,"agreement_no":202501072348},"after":null,"source":{"version":"2.7.3.Final","connector":"mysql","name":"MySqlConnector1","ts_ms":1736274470000,"snapshot":"false","db":"mysqldb","sequence":null,"ts_us":1736274470000000,"ts_ns":1736274470000000000,"table":"custinfo","server_id":8383,"gtid":null,"file":"mysql-bin.000013","pos":12257,"row":0,"thread":2245,"query":null},"transaction":null,"op":"d","ts_ms":1736274470622,"ts_us":1736274470622622,"ts_ns":1736274470622622128}
2025-01-07 18:27:50,820 - my_logger - INFO - Decoded key: {"mobile":9999910049}
2025-01-07 18:27:50,821 - my_logger - INFO - CDC OPeration is: d
2025-01-07 18:27:50,826 - my_logger - INFO - d operation: Deleted Redis Hash field: MySqlConnector1.mysqldb.custinfo[{"mobile":9999910049}]
2025-01-07 18:27:50,839 - my_logger - INFO - Offset committed for message at offset: 77
2025-01-07 18:27:50,839 - my_logger - INFO - Raw value: None
2025-01-07 18:27:50,839 - my_logger - INFO - Raw key: b'{"mobile":9999910049}'
2025-01-07 18:27:50,839 - my_logger - INFO - Decoded value: None
2025-01-07 18:27:50,839 - my_logger - INFO - Decoded key: {"mobile":9999910049}
2025-01-07 18:27:50,839 - my_logger - WARNING - Invalid value. Skipping Redis operation.
2025-01-07 18:27:50,850 - my_logger - INFO - Offset committed for message at offset: 78


FT.CREATE idx:MySqlConnector1.mysqldb.custinfo ON hash PREFIX 1 MySqlConnector1.mysqldb.custinfo SCHEMA '\"mobile\":' TEXT SORTABLE


mobile
$.pan_no AS pan_no TEXT 
$.aadhaar_no AS mobilaadhaar_noe TEXT 
$.enrollment_no AS enrollment_no TEXT 
$.certification AS certification TEXT 
$.total_amt AS total_amt TEXT 
$.payment AS payment TEXT 
$.pending AS pending TEXT 
$.duedate AS duedate TEXT 
$.fname AS fname TEXT 
$.mname AS mname TEXT 
$.lname AS lname TEXT 
$.emailid AS emailid TEXT 

FT.CREATE stud360  ON JSON PREFIX 3 "MySqlConnector1.mysqldb.studentpii:" "SqlServerConnector.mssqldb1.dbo.studentname:" "PostgresConnector.course.studentcert:" SCHEMA $.mobile AS mobile TEXT $.pan_no AS pan_no TEXT $.aadhaar_no AS aadhaar_no TEXT $.enrollment_no AS enrollment_no TEXT $.certification AS certification TEXT $.total_amt AS total_amt TEXT $.payment AS payment TEXT $.pending AS pending TEXT $.duedate AS duedate TEXT $.fname AS fname TEXT $.mname AS mname TEXT $.lname AS lname TEXT $.emailid AS emailid TEXT 

FT.CREATE stud360  ON JSON PREFIX 1 "MySqlConnector1.mysqldb.studentpii:" SCHEMA $.mobile AS mobile NUMERIC $.pan_no AS pan_no TEXT $.aadhaar_no AS aadhaar_no NUMERIC $.enrollment_no AS enrollment_no NUMERIC

JSON.SET sample_bicycle:1001 $ '{"model":"Racer","brand":"Speedster","price":320,"type":"Road","specs":{"material":"carbon fiber","weight":8},"description":"The Racer is built for speed and performance on the road!","addons":["water bottle holder","bike lock"],"helmet_included":true, "condition":"new"}'
JSON.SET sample_bicycle:1002 $ '{"model":"Explorer","brand":"Trailblazer","price":450,"type":"Mountain","specs":{"material":"steel","weight":15},"description":"The Explorer is your ultimate companion for off-road adventures!","addons":["mudguards","bike lights"],"helmet_included":true, "condition":"new"}'


> JSON.GET sample_bicycle:1001
"{\"model\":\"Racer\",\"brand\":\"Speedster\",\"price\":320,\"type\":\"Road\",\"specs\":{\"material\":\"carbon fiber\",\"weight\":8},\"description\":\"The Racer is built for speed and performance on the road!\",\"addons\":[\"water bottle holder\",\"bike lock\"],\"helmet_included\":true,\"condition\":\"new\"}"

> JSON.GET MySqlConnector1.mysqldb.studentpii:9000001487
"{\"mobile\":9000001487,\"pan_no\":\"ZZZZZ1487\",\"aadhaar_no\":\"999999991487\",\"enrollment_no\":\"1008999992974\"}"


FT.CREATE idx:stud360-1 ON JSON PREFIX 1 MySqlConnector1.mysqldb.studentpii: SCHEMA $.mobile AS mobile NUMERIC $.pan_no AS pan_no TEXT  $.aadhaar_no AS aadhaar_no TEXT $.enrollment_no AS enrollment_no TEXT 

JSON.GET PostgresConnector.course.studentcert:9000000001
"{\"mobile\":9000000001,\"certification\":\"GCP PCA\",\"total_amt\":25000,\"payment\":5000,\"pending\":20000,\"duedate\":\"24-Jan-2026\"}"

FT.CREATE idx:stud360-2 ON JSON PREFIX 2 MySqlConnector1.mysqldb.studentpii: PostgresConnector.course.studentcert: SCHEMA $.mobile AS mobile NUMERIC $.pan_no AS pan_no TEXT  $.aadhaar_no AS aadhaar_no TEXT $.enrollment_no AS enrollment_no TEXT $.certification AS certification TEXT $.total_amt AS total_amt NUMERIC $.payment AS payment NUMERIC $.pending AS pending NUMERIC $.duedate AS duedate TEXT 

FT.CREATE idx:stud360-2 ON JSON PREFIX 2 MySqlConnector1.mysqldb.studentpii: PostgresConnector.course.studentcert: SCHEMA $.mobile AS mobile NUMERIC $.pan_no AS pan_no TEXT  $.aadhaar_no AS aadhaar_no TEXT $.enrollment_no AS enrollment_no TEXT $.certification AS certification TEXT $.total_amt AS total_amt NUMERIC $.payment AS payment NUMERIC $.pending AS pending NUMERIC $.duedate AS duedate TEXT 

> FT.SEARCH idx:stud360-2 "@mobile:[9000000001 9000000002]"

> FT.SEARCH idx:stud360-2 "ZZZZZ0047"

> FT.SEARCH idx:stud360-2 "@mobile:[9000000001 9000000002]"
1) "4"
2) "MySqlConnector1.mysqldb.studentpii:9000000001"
3) 1) "$"
   2) "{\"mobile\":9000000001,\"pan_no\":\"ZZZZZ0001\",\"aadhaar_no\":\"999999990001\",\"enrollment_no\":\"1008999990002\"}"
4) "PostgresConnector.course.studentcert:9000000002"
5) 1) "$"
   2) "{\"mobile\":9000000002,\"certification\":\"Kafka Admin\",\"total_amt\":20000,\"payment\":5200,\"pending\":14800,\"duedate\":\"24-Jan-2026\"}"
6) "MySqlConnector1.mysqldb.studentpii:9000000002"
7) 1) "$"
   2) "{\"mobile\":9000000002,\"pan_no\":\"ZZZZZ0002\",\"aadhaar_no\":\"999999990002\",\"enrollment_no\":\"1008999990004\"}"
8) "PostgresConnector.course.studentcert:9000000001"
9) 1) "$"
   2) "{\"mobile\":9000000001,\"certification\":\"GCP PCA\",\"total_amt\":25000,\"payment\":5000,\"pending\":20000,\"duedate\":\"24-Jan-2026\"}"

1. Search for an Exact Mobile Number
> FT.SEARCH idx:stud360-2 "@mobile:[9000000001 9000000001]"
1) "2"
2) "MySqlConnector1.mysqldb.studentpii:9000000001"
3) 1) "$"
   2) "{\"mobile\":9000000001,\"pan_no\":\"ZZZZZ0001\",\"aadhaar_no\":\"999999990001\",\"enrollment_no\":\"1008999990002\"}"
4) "PostgresConnector.course.studentcert:9000000001"
5) 1) "$"
   2) "{\"mobile\":9000000001,\"certification\":\"GCP PCA\",\"total_amt\":25000,\"payment\":5000,\"pending\":20000,\"duedate\":\"24-Jan-2026\"}"


> JSON.GET SqlServerConnector.mssqldb1.dbo.studentname:9000000001
"{\"mobile\":9000000001,\"fname\":\"First1\",\"mname\":\"M1\",\"lname\":\"Last1\",\"emailid\":\"First1Last1@srilab83.org\"}"


FT.CREATE idx:stud360-3 ON JSON PREFIX 3 MySqlConnector1.mysqldb.studentpii: PostgresConnector.course.studentcert: SqlServerConnector.mssqldb1.dbo.studentname: SCHEMA $.mobile AS mobile NUMERIC $.pan_no AS pan_no TEXT  $.aadhaar_no AS aadhaar_no TEXT $.enrollment_no AS enrollment_no TEXT $.certification AS certification TEXT $.total_amt AS total_amt NUMERIC $.payment AS payment NUMERIC $.pending AS pending NUMERIC $.duedate AS duedate TEXT $.fname AS fname TEXT $.mname AS mname TEXT $.lname AS lname TEXT $.emailid AS emailid TEXT

> FT.CREATE idx:stud360-3 ON JSON PREFIX 3 MySqlConnector1.mysqldb.studentpii: PostgresConnector.course.studentcert: SqlServerConnector.mssqldb1.dbo.studentname: SCHEMA $.mobile AS mobile NUMERIC $.pan_no AS pan_no TEXT $.aadhaar_no AS aadhaar_no TEXT $.enrollment_no AS enrollment_no TEXT $.certification AS certification TEXT $.total_amt AS total_amt NUMERIC $.payment AS payment NUMERIC $.pending AS pending NUMERIC $.duedate AS duedate TEXT $.fname AS fname TEXT $.mname AS mname TEXT $.lname AS lname TEXT $.emailid AS emailid TEXT
"OK"


> FT.SEARCH idx:stud360-3 "@mobile:[9000000001 9000000001]"
1) "3"
2) "MySqlConnector1.mysqldb.studentpii:9000000001"
3) 1) "$"
   2) "{\"mobile\":9000000001,\"pan_no\":\"ZZZZZ0001\",\"aadhaar_no\":\"999999990001\",\"enrollment_no\":\"1008999990002\"}"
4) "SqlServerConnector.mssqldb1.dbo.studentname:9000000001"
5) 1) "$"
   2) "{\"mobile\":9000000001,\"fname\":\"First1\",\"mname\":\"M1\",\"lname\":\"Last1\",\"emailid\":\"First1Last1@srilab83.org\"}"
6) "PostgresConnector.course.studentcert:9000000001"
7) 1) "$"
   2) "{\"mobile\":9000000001,\"certification\":\"GCP PCA\",\"total_amt\":25000,\"payment\":5000,\"pending\":20000,\"duedate\":\"24-Jan-2026\"}"
> 
